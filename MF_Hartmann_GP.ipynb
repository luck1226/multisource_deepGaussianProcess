{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from emukit.test_functions.multi_fidelity import multi_fidelity_hartmann_3d\n",
    "from emukit.core import ContinuousParameter, ParameterSpace\n",
    "from emukit.core.initial_designs import LatinDesign\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "Function = namedtuple('Function', ['name', 'y_scale', 'noise_level', 'do_x_scaling', 'num_data', 'fcn'])\n",
    "\n",
    "\n",
    "hartmann_3d = Function(name='hartmann', y_scale=1, noise_level=[0., 0., 0.], do_x_scaling=True, num_data=[80, 40, 20], \n",
    "                    fcn=multi_fidelity_hartmann_3d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(fcn_tuple, n_test_points):\n",
    "    \"\"\"\n",
    "    Generates train and test data for\n",
    "    \"\"\"\n",
    "    \n",
    "    # A different definition of the parameter space for the branin function was used in the paper\n",
    "    if fcn_tuple.name == 'branin':\n",
    "        fcn, space = fcn_tuple.fcn()\n",
    "        new_space = ParameterSpace([ContinuousParameter('x1', -5., 0.), ContinuousParameter('x2', 10., 15.)])\n",
    "    else:\n",
    "        fcn, space = fcn_tuple.fcn()\n",
    "        new_space = ParameterSpace(space._parameters[:-1])\n",
    "    \n",
    "    do_x_scaling = fcn_tuple.do_x_scaling\n",
    "    \n",
    "    \n",
    "    # Generate training data\n",
    "    \n",
    "    latin = LatinDesign(new_space)\n",
    "    X = [latin.get_samples(n) for n in fcn_tuple.num_data]\n",
    "    \n",
    "    # Scale X if required\n",
    "    if do_x_scaling:\n",
    "        scalings = X[0].std(axis=0)\n",
    "    else:\n",
    "        scalings = np.ones(X[0].shape[1])\n",
    "        \n",
    "    for x in X:\n",
    "        x /= scalings\n",
    "    \n",
    "    Y = []\n",
    "    for i, x in enumerate(X):\n",
    "        Y.append(fcn.f[i](x * scalings))\n",
    "    \n",
    "    y_scale = fcn_tuple.y_scale\n",
    "    \n",
    "    # scale y and add noise if required\n",
    "    noise_levels = fcn_tuple.noise_level\n",
    "    if any([n > 0 for n in noise_levels]):\n",
    "        for y, std_noise in zip(Y, noise_levels):\n",
    "            y /= y_scale + std_noise * np.random.randn(y.shape[0], 1)\n",
    "    \n",
    "    # Generate test data\n",
    "    x_test = latin.get_samples(n_test_points)\n",
    "    x_test /= scalings\n",
    "    y_test = fcn.f[-1](x_test * scalings)\n",
    "    y_test /= y_scale\n",
    "\n",
    "    i_highest_fidelity = (len(fcn_tuple.num_data) - 1) * np.ones((x_test.shape[0], 1))\n",
    "    x_test = np.concatenate([x_test, i_highest_fidelity], axis=1)\n",
    "    print(X[1].shape)\n",
    "    return x_test, y_test, X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_test, y_mean_prediction, y_var_prediction):\n",
    "    # R2\n",
    "    r2 = r2_score(y_test, y_mean_prediction)\n",
    "    # RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_mean_prediction))\n",
    "    # Test log likelihood\n",
    "    mnll = -np.sum(scipy.stats.norm.logpdf(y_test, loc=y_mean_prediction, scale=np.sqrt(y_var_prediction)))/len(y_test)\n",
    "    return {'r2': r2, 'rmse': rmse, 'mnll': mnll}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 3)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "\n",
    "x_test, y_test, X, Y = generate_data(hartmann_3d, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((80, 3), (80, 1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].shape, Y[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40, 3), (40, 1))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1].shape, Y[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20, 3), (20, 1))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[2].shape, Y[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 4), (1000, 1))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduce AR1 model and fit all three fidelities of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from emukit.examples.multi_fidelity_dgp.baseline_model_wrappers import LinearAutoRegressiveModel\n",
    "\n",
    "#m1 =  LinearAutoRegressiveModel(X, Y)\n",
    "#m1.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_mean, y_var = m1.predict(x_test)\n",
    "\n",
    "import scipy.stats\n",
    "\n",
    "#print(calculate_metrics(y_test, y_mean, y_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#plt.scatter(y_mean,y_test)\n",
    "#plt.plot([0, 1], [0, 1], '--k', transform=plt.gca().transAxes)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To set up the data in three-layer structure\n",
    "### Cheap data, expensive data, high data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<paramz.optimization.optimization.opt_lbfgsb at 0x7fed89713590>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_branin_cheap = X[0]\n",
    "X_branin_expensive = X[1]\n",
    "X_branin_high = X[2]\n",
    "\n",
    "y_branin_cheap = Y[0]\n",
    "y_branin_expensive = Y[1]\n",
    "y_branin_high = Y[2]\n",
    "\n",
    "import GPy\n",
    "#from GPy.kern import Kern\n",
    "#from GPy import Param, Model\n",
    "\n",
    "m2 = GPy.models.GPRegression(X_branin_high, y_branin_high)\n",
    "m2.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization restart 1/10, f = 21.94988305449211\n",
      "Optimization restart 2/10, f = 21.949883045945406\n",
      "Optimization restart 3/10, f = 21.949883075440255\n",
      "Optimization restart 4/10, f = 21.949883271473936\n",
      "Optimization restart 5/10, f = 21.949884365553636\n",
      "Optimization restart 6/10, f = 36.458681287728496\n",
      "Optimization restart 7/10, f = 21.94988316413083\n",
      "Optimization restart 8/10, f = 21.949883255899408\n",
      "Optimization restart 9/10, f = 21.949884403351515\n",
      "Optimization restart 10/10, f = 21.949883206121704\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<paramz.optimization.optimization.opt_lbfgsb at 0x7fed89713590>,\n",
       " <paramz.optimization.optimization.opt_lbfgsb at 0x7fed8884ac90>,\n",
       " <paramz.optimization.optimization.opt_lbfgsb at 0x7fed88846c90>,\n",
       " <paramz.optimization.optimization.opt_lbfgsb at 0x7fed89714c90>,\n",
       " <paramz.optimization.optimization.opt_lbfgsb at 0x7fed894b5450>,\n",
       " <paramz.optimization.optimization.opt_lbfgsb at 0x7fed89668110>,\n",
       " <paramz.optimization.optimization.opt_lbfgsb at 0x7fed89e20e10>,\n",
       " <paramz.optimization.optimization.opt_lbfgsb at 0x7fed8884ab90>,\n",
       " <paramz.optimization.optimization.opt_lbfgsb at 0x7fed897133d0>,\n",
       " <paramz.optimization.optimization.opt_lbfgsb at 0x7fed89713110>,\n",
       " <paramz.optimization.optimization.opt_lbfgsb at 0x7fed89713190>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2.optimize_restarts(num_restarts = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Name : GP regression\n",
      "Objective : 21.949883045945406\n",
      "Number of Parameters : 3\n",
      "Number of Optimization Parameters : 3\n",
      "Updates : True\n",
      "Parameters:\n",
      "  \u001b[1mGP_regression.         \u001b[0;0m  |                  value  |  constraints  |  priors\n",
      "  \u001b[1mrbf.variance           \u001b[0;0m  |     1.3127777499545188  |      +ve      |        \n",
      "  \u001b[1mrbf.lengthscale        \u001b[0;0m  |     1.1911552283245153  |      +ve      |        \n",
      "  \u001b[1mGaussian_noise.variance\u001b[0;0m  |  2.395569501118192e-09  |      +ve      |        \n"
     ]
    }
   ],
   "source": [
    "print(m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.3127777499545188, 1.1911552283245153)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2.kern.variance[0], m2.kern.lengthscale[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = x_test[:,0:3]\n",
    "X_test.shape\n",
    "#Y_test=[]\n",
    "#Y_test_std = []\n",
    "#Y_test_up=[]\n",
    "#Y_test_down=[]\n",
    "\n",
    "#for i in range(X_test.shape[0]):\n",
    "#    xx = X_test[i].reshape(1,2)\n",
    "#    Xnew = np.vstack((xx,X_currin_expensive))\n",
    "#    mu1, v1 = m4.predict(Xnew, full_cov = True)\n",
    "#    kernMF = MFRBF(input_dim=2,variance = s2, lengthscale = l2, mu = mu1, v=v1)\n",
    "#    kernRBF = GPy.kern.RBF(input_dim = 2, variance = s1, lengthscale = l1)\n",
    "#    M1 = kernMF.K(Xnew)\n",
    "#    M2 = kernRBF.K(Xnew)\n",
    "#    GG = np.multiply(M1, M2)\n",
    "    \n",
    "#    pred_mu, pred_std = predict_eff(GG, y_currin_expensive)\n",
    "    \n",
    "#    Y_test.append(pred_mu)\n",
    "#    Y_test_std.append(pred_std)\n",
    "#    Y_test_up.append(pred_mu+1.96*pred_std)\n",
    "#    Y_test_down.append(pred_mu-1.96*pred_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu12_3, var12_3 = m2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#var12_3 = np.diagonal(cov12_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mu12_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#var12_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#var12_3=np.array(var12_3).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'r2': 0.7783692171350265, 'rmse': 0.44246306908238475, 'mnll': 0.6762800855636001}\n"
     ]
    }
   ],
   "source": [
    "print(calculate_metrics(y_test, mu12_3, var12_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
